const fs = require('fs');
const path = require('path');

// –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è Whisper - –≤ production –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è OpenAI Whisper API
class WhisperService {
  constructor() {
    this.supportedLanguages = ['en', 'ru', 'de', 'es', 'cs', 'pl', 'lt', 'lv', 'no'];
    console.log('üé§ Whisper Service initialized (mock mode)');
  }

  async transcribe(audioFilePath, language = 'auto') {
    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
      if (!fs.existsSync(audioFilePath)) {
        throw new Error('Audio file not found');
      }

      // –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –≤—ã–∑–æ–≤ Whisper API
      // –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
      const mockTranscription = `Sample transcription for audio file in ${language} language`;
      
      console.log(`üé§ Transcribed audio file: ${path.basename(audioFilePath)}`);

      return {
        text: mockTranscription,
        language: language === 'auto' ? 'en' : language,
        confidence: 0.95,
        duration: 5.0,
        provider: 'mock-whisper'
      };

    } catch (error) {
      console.error('Whisper Error:', error);
      throw new Error(`Speech recognition failed: ${error.message}`);
    }
  }
}

// –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
const whisperService = new WhisperService();

// –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
async function transcribeAudio(audioFilePath, language = 'auto') {
  const result = await whisperService.transcribe(audioFilePath, language);
  return result.text;
}

module.exports = {
  transcribeAudio,
  WhisperService,
  whisperService
};
